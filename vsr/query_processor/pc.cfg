# Note that the query term vectors need to have entries EVEN_FOR
# terms that appear in no queries at all!
# The term-space is equal to the DOCUMENT_TERM_SPACE
# In theory we would need to build a hybrid space consisting of all words
# found in queries AND documents, but since terms that only appear in queries
# will never match in documents then they will be zero anyhow.

[InputFiles]

# This is an XML file containing the queries to be run.
LEIA = ../data/cfquery.xml

# A CSV representation of the inverted index is needed to find out the indexes for query tokens
INVERTED_INDEX = ../inverted_index/output.csv

[OutputFiles]

# This is a CSV file where the queries read form the previous file will be rewritten,
# using the same filters used for processing documents, in order to normalize them.
CONSULTAS = queries.csv

# The expected results also need to be converted to our representation. They can be obtained 
# from the query XML file. They will be placed in the following file:
RESULTADOS = expected_query_results.csv


[Params]

# Tokens shorter than this value will not be considered when processing queries
TOKEN_LENGTH_THRESHOLD = 2

# If True, only Tokens where all characters are letters (no digits or special characters) will be
#   considered when processing queries.
ONLY_LETTERS = True

# If True, words in nltk's stop word list (augmented with a few custom words) will be stripped from the processed queries.
IGNORE_STOP_WORDS = True
